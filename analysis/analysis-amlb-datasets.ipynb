{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis AMLB Datasets\n",
    "\n",
    "Notebook for analysing and extracting metadata from the benchmarks used for Classification and Regression Tasks according to the OpenML AMLB benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from sklearn.datasets import fetch_openml\n",
    "import openml\n",
    "\n",
    "# setup the rcparams for the fonts\n",
    "plt.rcParams['axes.titlesize'] = 20     # Font size for plot title\n",
    "plt.rcParams['axes.titleweight'] = 'bold' # Font weight for plot title\n",
    "plt.rcParams['xtick.labelsize'] = 13    # Font size for x-tick labels\n",
    "plt.rcParams['ytick.labelsize'] = 13    # Font size for y-tick labels\n",
    "plt.rcParams['axes.labelsize'] = 16   # Font size for x-axis labels\n",
    "plt.rcParams['axes.labelweight'] = 'bold' # Font weight for x-axis labels\n",
    "plt.rcParams['legend.loc'] = 'lower right'\n",
    "plt.rcParams['legend.fontsize'] = 13\n",
    "plt.rcParams['legend.title_fontsize'] = 15\n",
    "# setup the rcparams for the figsize\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 10)\n",
    "plt.rcParams['savefig.dpi'] = 400\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['ps.fonttype'] = 42\n",
    "plt.rcParams['axes.facecolor']='white'\n",
    "plt.rcParams['savefig.facecolor']='white'\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datasets_metadata_classification(data):\n",
    "    metadata = {\n",
    "        'dataset' : data['details']['name'],\n",
    "        '#classes' : data.target.nunique(),\n",
    "        'dataset_id' : data['details']['id'],\n",
    "        'n_features' : data.data.shape[1],\n",
    "        'n_samples' : data.data.shape[0],\n",
    "        'size' : data.data.size,\n",
    "        'missings' : data.data.isnull().any().any(),\n",
    "        '#integer' : len(data.data.select_dtypes(include='integer').columns),\n",
    "        '#float' : len(data.data.select_dtypes(include='float').columns),\n",
    "        '#boolean' : len(data.data.select_dtypes(include='boolean').columns),\n",
    "        '#categorical' : len(data.data.select_dtypes(include='category').columns),\n",
    "        '#integerw/nans' : data.data.select_dtypes(include='integer').isnull().any().any(),\n",
    "        '#floatw/nans' : data.data.select_dtypes(include='float').isnull().any().any(),\n",
    "        '#booleanw/nans' : data.data.select_dtypes(include='boolean').isnull().any().any(),\n",
    "        '#categoricalw/nans' : data.data.select_dtypes(include='category').isnull().any().any()\n",
    "    }\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "amlb_classification_benchmark = 271"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = openml.study.get_suite(amlb_classification_benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, task_id in enumerate(benchmark.tasks):\n",
    "    try:\n",
    "        task = openml.tasks.get_task(task_id=task_id, download_splits=False, download_data=False)\n",
    "        data = fetch_openml(data_id=task.dataset_id, as_frame=True)\n",
    "        print(f'>> ({i+1}/{len(benchmark.tasks)}) {data[\"details\"][\"name\"]}')\n",
    "        metadata.append(get_datasets_metadata_classification(data))\n",
    "    except Exception as e:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/metadata/classification_datasets_metadata.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "edca",
   "language": "python",
   "name": "edca"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
