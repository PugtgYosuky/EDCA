{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse the best solutions achieved (overall best)\n",
    "\n",
    "Notebook to get the best solutions overall by each AutoML framework (EDCA, FLAML, TPOT). It gets the % data used, metrics values and the individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = list(sorted(['adult', 'Australian', 'cnae-9', 'credit-g', 'kr-vs-kp', 'mfeat-factors', 'bank-marketing', 'Amazon_employee_access']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EDCA best solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edca_best_models = {}\n",
    "for dataset in datasets:\n",
    "    models = []\n",
    "    mccs = []\n",
    "    sample_percentage = []\n",
    "    feature_percentage = []\n",
    "    for run in range(30):\n",
    "        path = os.path.join('..', 'thesis-results', 'datasets-divided', 'edca-1-0-0', dataset, f'run_{run}', 'results.json')\n",
    "        with open(path, 'r') as f:\n",
    "            results = json.load(f)\n",
    "            models = models + results['evo_best']\n",
    "            mccs = mccs + results['evo_mcc']\n",
    "            sample_percentage = sample_percentage + results['evo_sample_%']\n",
    "            feature_percentage = feature_percentage + results['evo_features_%']\n",
    "    edca_best_models[dataset] = {\n",
    "        'mcc' : mccs,\n",
    "        'models' : models,\n",
    "        'sample_percentage' : sample_percentage,\n",
    "        'feature_percentage' : feature_percentage\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "edca_values = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amazon_employee_access\n",
      "MCC 0.5046705324188538\n",
      "sample_percentage 0.75\n",
      "feature_percentage 0.5555555555555556\n",
      "\n",
      "Australian\n",
      "MCC 0.853097721950181\n",
      "sample_percentage 0.3278985507246377\n",
      "feature_percentage 1.0\n",
      "\n",
      "adult\n",
      "MCC 0.6571655945186987\n",
      "sample_percentage 0.6276040333725751\n",
      "feature_percentage 1.0\n",
      "\n",
      "bank-marketing\n",
      "MCC 0.5507043178463852\n",
      "sample_percentage 0.64035500013824\n",
      "feature_percentage 0.6875\n",
      "\n",
      "cnae-9\n",
      "MCC 0.9741932655154736\n",
      "sample_percentage 0.75\n",
      "feature_percentage 1.0\n",
      "\n",
      "credit-g\n",
      "MCC 0.466857415166512\n",
      "sample_percentage 0.4975\n",
      "feature_percentage 1.0\n",
      "\n",
      "kr-vs-kp\n",
      "MCC 1.0\n",
      "sample_percentage 0.7497066875244427\n",
      "feature_percentage 1.0\n",
      "\n",
      "mfeat-factors\n",
      "MCC 0.9833947974289856\n",
      "sample_percentage 0.75\n",
      "feature_percentage 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "for dataset in datasets:\n",
    "    print()\n",
    "    print(dataset)\n",
    "    df = pd.DataFrame(edca_best_models[dataset])\n",
    "    best = df.loc[df.mcc == df.mcc.max()]\n",
    "    print('MCC', best.mcc.values[0])\n",
    "    best_json = best.models.values[0]\n",
    "    if 'sample' in best_json:\n",
    "        _ = best_json.pop('sample')\n",
    "    if 'features' in best_json:\n",
    "        _ = best_json.pop('features')\n",
    "    print('sample_percentage', best.sample_percentage.values[0])\n",
    "    print('feature_percentage', best.feature_percentage.values[0])\n",
    "    aux = {}\n",
    "    aux['sample_percentage'] = round(best.sample_percentage.values[0], 2)\n",
    "    aux['feature_percentage'] = round(best.feature_percentage.values[0], 2)\n",
    "    for key, value in best_json.items():\n",
    "        if isinstance(value, dict):\n",
    "            aux[key] = list(value.keys())[0]\n",
    "        else:\n",
    "            aux[key] = value\n",
    "    edca_values[dataset] = aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "edca_df = pd.DataFrame(edca_values).T\n",
    "edca_df.reset_index(inplace=True)\n",
    "edca_df = edca_df.rename(columns={'index': 'dataset'})\n",
    "edca_df.insert(1, 'Framework', 'EDCA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Framework</th>\n",
       "      <th>sample_percentage</th>\n",
       "      <th>feature_percentage</th>\n",
       "      <th>scaler</th>\n",
       "      <th>model</th>\n",
       "      <th>categorical-imputer</th>\n",
       "      <th>encoder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon_employee_access</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SimpleImputer</td>\n",
       "      <td>OneHotEncoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bank-marketing</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.69</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OneHotEncoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnae-9</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>credit-g</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OneHotEncoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OneHotEncoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mfeat-factors</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.78</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset Framework sample_percentage feature_percentage  \\\n",
       "0  Amazon_employee_access      EDCA              0.75               0.56   \n",
       "1              Australian      EDCA              0.33                1.0   \n",
       "2                   adult      EDCA              0.63                1.0   \n",
       "3          bank-marketing      EDCA              0.64               0.69   \n",
       "4                  cnae-9      EDCA              0.75                1.0   \n",
       "5                credit-g      EDCA               0.5                1.0   \n",
       "6                kr-vs-kp      EDCA              0.75                1.0   \n",
       "7           mfeat-factors      EDCA              0.75               0.78   \n",
       "\n",
       "           scaler                   model categorical-imputer        encoder  \n",
       "0    MinMaxScaler  RandomForestClassifier                 NaN            NaN  \n",
       "1    MinMaxScaler           XGBClassifier                 NaN            NaN  \n",
       "2  StandardScaler           XGBClassifier       SimpleImputer  OneHotEncoder  \n",
       "3    MinMaxScaler           XGBClassifier                 NaN  OneHotEncoder  \n",
       "4  StandardScaler      LogisticRegression                 NaN            NaN  \n",
       "5    RobustScaler      LogisticRegression                 NaN  OneHotEncoder  \n",
       "6             NaN  RandomForestClassifier                 NaN  OneHotEncoder  \n",
       "7  StandardScaler      LogisticRegression                 NaN            NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edca_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLAML bests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaml_best_models = {}\n",
    "for dataset in datasets:\n",
    "    models = []\n",
    "    mccs = []\n",
    "    sample_percentage = []\n",
    "    feature_percentage = []\n",
    "    for run in range(30):\n",
    "        path = os.path.join('..', 'thesis-results', 'datasets-divided', 'flaml', dataset, f'run_{run}', 'results.json')\n",
    "        with open(path, 'r') as f:\n",
    "            results = json.load(f)\n",
    "            models = models + results['flaml_best_learner']\n",
    "            mccs = mccs + results['flaml_mcc']\n",
    "            sample_percentage = sample_percentage + results['flaml_sample_%']\n",
    "            feature_percentage = feature_percentage + results['flaml_features_%']\n",
    "    flaml_best_models[dataset] = {\n",
    "        'mcc' : mccs,\n",
    "        'models' : models,\n",
    "        'sample_percentage' : sample_percentage,\n",
    "        'feature_percentage' : feature_percentage\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amazon_employee_access\n",
      "MCC 0.4832211417745258\n",
      "lgbm\n",
      "sample_percentage 0.7499904634751097\n",
      "feature_percentage 1.0\n",
      "\n",
      "Australian\n",
      "MCC 0.8535852770771386\n",
      "xgb_limitdepth\n",
      "sample_percentage 0.75\n",
      "feature_percentage 1.0\n",
      "\n",
      "adult\n",
      "MCC 0.6585489292783278\n",
      "lgbm\n",
      "sample_percentage 0.7499808051595731\n",
      "feature_percentage 1.0\n",
      "\n",
      "bank-marketing\n",
      "MCC 0.5534720079137596\n",
      "lgbm\n",
      "sample_percentage 0.7499792640106169\n",
      "feature_percentage 1.0\n",
      "\n",
      "cnae-9\n",
      "MCC 0.968820085006422\n",
      "xgb_limitdepth\n",
      "sample_percentage 0.75\n",
      "feature_percentage 1.0\n",
      "\n",
      "credit-g\n",
      "MCC 0.5773728780150095\n",
      "lgbm\n",
      "sample_percentage 0.75\n",
      "feature_percentage 1.0\n",
      "\n",
      "kr-vs-kp\n",
      "\n",
      "mfeat-factors\n",
      "MCC 0.98615220164225\n",
      "xgboost\n",
      "sample_percentage 0.75\n",
      "feature_percentage 1.0\n"
     ]
    }
   ],
   "source": [
    "flaml_values = {}\n",
    "for dataset in datasets:\n",
    "    print()\n",
    "    print(dataset)\n",
    "    df = pd.DataFrame(flaml_best_models[dataset])\n",
    "    try:\n",
    "        best = df.loc[df.mcc == df.mcc.max()]\n",
    "        print('MCC', best.mcc.values[0])\n",
    "        print(best.models.values[0])\n",
    "        print('sample_percentage', best.sample_percentage.values[0])\n",
    "        print('feature_percentage', best.feature_percentage.values[0])\n",
    "        aux = {}\n",
    "        aux['sample_percentage'] = round(best.sample_percentage.values[0], 2)\n",
    "        aux['feature_percentage'] = round(best.feature_percentage.values[0], 2)\n",
    "        aux['model'] = best.models.values[0]\n",
    "        flaml_values[dataset] = aux\n",
    "    except:\n",
    "        flaml_values[dataset] = {}\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaml_df = pd.DataFrame(flaml_values).T\n",
    "flaml_df.reset_index(inplace=True)\n",
    "flaml_df = flaml_df.rename(columns={'index': 'dataset'})\n",
    "flaml_df.insert(1, 'Framework', 'FLAML')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Framework</th>\n",
       "      <th>sample_percentage</th>\n",
       "      <th>feature_percentage</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon_employee_access</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lgbm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australian</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>xgb_limitdepth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lgbm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bank-marketing</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lgbm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnae-9</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>xgb_limitdepth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>credit-g</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>lgbm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mfeat-factors</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>xgboost</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset Framework sample_percentage feature_percentage  \\\n",
       "0  Amazon_employee_access     FLAML              0.75                1.0   \n",
       "1              Australian     FLAML              0.75                1.0   \n",
       "2                   adult     FLAML              0.75                1.0   \n",
       "3          bank-marketing     FLAML              0.75                1.0   \n",
       "4                  cnae-9     FLAML              0.75                1.0   \n",
       "5                credit-g     FLAML              0.75                1.0   \n",
       "6                kr-vs-kp     FLAML               NaN                NaN   \n",
       "7           mfeat-factors     FLAML              0.75                1.0   \n",
       "\n",
       "            model  \n",
       "0            lgbm  \n",
       "1  xgb_limitdepth  \n",
       "2            lgbm  \n",
       "3            lgbm  \n",
       "4  xgb_limitdepth  \n",
       "5            lgbm  \n",
       "6             NaN  \n",
       "7         xgboost  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flaml_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaml_models_map = {\n",
    "    'lgbm' : 'LGBMClassifier',\n",
    "    'xgboost' : 'XGBClassifier',\n",
    "    'xgb_limitdepth' : 'XGBClassifier',\n",
    "    'rf' : 'RandomForestClassifier',\n",
    "    'lrl1' : 'LogisticRegression',\n",
    "    'lrl2' : 'LogisticRegression',\n",
    "    'kneighbor' : 'KNeighborsClassifier',\n",
    "    'extra_tree' : 'ExtraTreesClassifier',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "flaml_df.model = flaml_df.model.map(flaml_models_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TPOT bests\n",
    "tpot_best_models = {}\n",
    "for dataset in datasets:\n",
    "    models = []\n",
    "    mccs = []\n",
    "    sample_percentage = []\n",
    "    feature_percentage = []\n",
    "    for run in range(30):\n",
    "        path = os.path.join('..', 'thesis-results', 'datasets-divided', 'tpot', dataset, f'run_{run}', 'results.json')\n",
    "        with open(path, 'r') as f:\n",
    "            results = json.load(f)\n",
    "            models = models + results['tpot_best_pipeline']\n",
    "            mccs = mccs + results['tpot_mcc']\n",
    "            sample_percentage = sample_percentage + results['tpot_sample_%']\n",
    "            feature_percentage = feature_percentage + results['tpot_features_%']\n",
    "    tpot_best_models[dataset] = {\n",
    "        'mcc' : mccs,\n",
    "        'models' : models,\n",
    "        'sample_percentage' : sample_percentage,\n",
    "        'feature_percentage' : feature_percentage\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Amazon_employee_access\n",
      "MCC 0.5377234798413941\n",
      "[('stackingestimator', StackingEstimator(estimator=RandomForestClassifier(bootstrap=False,\n",
      "                                                   criterion='entropy',\n",
      "                                                   max_features=0.25,\n",
      "                                                   min_samples_leaf=4,\n",
      "                                                   min_samples_split=8,\n",
      "                                                   random_state=522))), ('extratreesclassifier', ExtraTreesClassifier(max_features=0.35000000000000003, min_samples_leaf=13,\n",
      "                     min_samples_split=18, random_state=522))]\n",
      "sample_percentage 1.0\n",
      "feature_percentage 1.0\n",
      "\n",
      "Australian\n",
      "MCC 0.8271742062290949\n",
      "[('rfe', RFE(estimator=ExtraTreesClassifier(max_features=0.3, random_state=28),\n",
      "    step=0.7000000000000001)), ('lgbmclassifier', LGBMClassifier(colsample_bytree=0.5, learning_rate=0.01, min_child_samples=22,\n",
      "               n_estimators=377, num_leaves=719, random_state=28, verbosity=-1))]\n",
      "sample_percentage 1.0\n",
      "feature_percentage 0.5\n",
      "\n",
      "adult\n",
      "\n",
      "bank-marketing\n",
      "\n",
      "cnae-9\n",
      "MCC 0.9793083592608048\n",
      "[('stackingestimator', StackingEstimator(estimator=ExtraTreesClassifier(bootstrap=True,\n",
      "                                                 criterion='entropy',\n",
      "                                                 max_features=0.15000000000000002,\n",
      "                                                 min_samples_leaf=3,\n",
      "                                                 min_samples_split=9,\n",
      "                                                 random_state=309))), ('standardscaler', StandardScaler()), ('logisticregression', LogisticRegression(C=0.1, random_state=309))]\n",
      "sample_percentage 1.0\n",
      "feature_percentage 1.0116822429906542\n",
      "\n",
      "credit-g\n",
      "\n",
      "kr-vs-kp\n",
      "\n",
      "mfeat-factors\n",
      "MCC 0.9889232270971007\n",
      "[('standardscaler', StandardScaler()), ('logisticregression', LogisticRegression(C=10.0, random_state=872))]\n",
      "sample_percentage 1.0\n",
      "feature_percentage 1.0\n"
     ]
    }
   ],
   "source": [
    "tpot_values = {}\n",
    "for dataset in datasets:\n",
    "    print()\n",
    "    print(dataset)\n",
    "    try:\n",
    "        df = pd.DataFrame(tpot_best_models[dataset])\n",
    "        best = df.loc[df.mcc == df.mcc.max()]\n",
    "        print('MCC', best.mcc.values[0])\n",
    "        print(best.models.values[0])\n",
    "        print('sample_percentage', best.sample_percentage.values[0])\n",
    "        print('feature_percentage', best.feature_percentage.values[0])\n",
    "        tpot_values[dataset] = best.models.values[0]\n",
    "    except:\n",
    "        tpot_values[dataset] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpot_values = {\n",
    "    'Amazon_employee_access' : {\n",
    "        'sample_percentage' : 1.0,\n",
    "        'feature_percentage' : 1.0,\n",
    "        'model' : 'StackingEstimator (RandomForestClassifier, ExtraTreesClassifier)'\n",
    "    },\n",
    "    'adult' : {},\n",
    "    'Australian' : {\n",
    "        'sample_percentage' : 1.0,\n",
    "        'feature_percentage' : f'0.5 (RFE)',\n",
    "        'model' : 'LGBMClassifier'\n",
    "    },\n",
    "    'bank-marketing' : {},\n",
    "    'cnae-9' : {\n",
    "        'sample_percentage' : 1.0, \n",
    "        'feature_percentage' : 1.0,\n",
    "        'model' : 'StackingEstimator (ExtraTreesClassifier, StandardScaler, LogisticRegression)'\n",
    "    },\n",
    "    'credit-g' : {},\n",
    "    'kr-vs-kp' : {},\n",
    "    'mfeat-factors' : {\n",
    "        'sample_percentage' : 1.0, \n",
    "        'feature_percentage' : 1.0,\n",
    "        'scaler' : 'StandardScaler',\n",
    "        'model' : 'LogisticRegression'\n",
    "    }\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Framework</th>\n",
       "      <th>sample_percentage</th>\n",
       "      <th>feature_percentage</th>\n",
       "      <th>model</th>\n",
       "      <th>scaler</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Amazon_employee_access</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>StackingEstimator (RandomForestClassifier, Ext...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australian</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5 (RFE)</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bank-marketing</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnae-9</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>StackingEstimator (ExtraTreesClassifier, Stand...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>credit-g</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mfeat-factors</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>StandardScaler</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset Framework sample_percentage feature_percentage  \\\n",
       "0  Amazon_employee_access      TPOT               1.0                1.0   \n",
       "1                   adult      TPOT               NaN                NaN   \n",
       "2              Australian      TPOT               1.0          0.5 (RFE)   \n",
       "3          bank-marketing      TPOT               NaN                NaN   \n",
       "4                  cnae-9      TPOT               1.0                1.0   \n",
       "5                credit-g      TPOT               NaN                NaN   \n",
       "6                kr-vs-kp      TPOT               NaN                NaN   \n",
       "7           mfeat-factors      TPOT               1.0                1.0   \n",
       "\n",
       "                                               model          scaler  \n",
       "0  StackingEstimator (RandomForestClassifier, Ext...             NaN  \n",
       "1                                                NaN             NaN  \n",
       "2                                     LGBMClassifier             NaN  \n",
       "3                                                NaN             NaN  \n",
       "4  StackingEstimator (ExtraTreesClassifier, Stand...             NaN  \n",
       "5                                                NaN             NaN  \n",
       "6                                                NaN             NaN  \n",
       "7                                 LogisticRegression  StandardScaler  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tpot_df = pd.DataFrame(tpot_values).T\n",
    "tpot_df.reset_index(inplace=True)\n",
    "tpot_df = tpot_df.rename(columns={'index': 'dataset'})\n",
    "tpot_df.insert(1, 'Framework', 'TPOT')\n",
    "tpot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Framework</th>\n",
       "      <th>sample_percentage</th>\n",
       "      <th>feature_percentage</th>\n",
       "      <th>scaler</th>\n",
       "      <th>model</th>\n",
       "      <th>categorical-imputer</th>\n",
       "      <th>encoder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.63</td>\n",
       "      <td>1.0</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>SimpleImputer</td>\n",
       "      <td>OneHotEncoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon_employee_access</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.56</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon_employee_access</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon_employee_access</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>StackingEstimator (RandomForestClassifier, Ext...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>australian</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.33</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>australian</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>australian</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5 (RFE)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bank-marketing</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.69</td>\n",
       "      <td>MinMaxScaler</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OneHotEncoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bank-marketing</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bank-marketing</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnae-9</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnae-9</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnae-9</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>StackingEstimator (ExtraTreesClassifier, Stand...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>credit-g</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>RobustScaler</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OneHotEncoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>credit-g</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>LGBMClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>credit-g</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OneHotEncoder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kr-vs-kp</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mfeat-factors</td>\n",
       "      <td>EDCA</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.78</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mfeat-factors</td>\n",
       "      <td>FLAML</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>XGBClassifier</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>mfeat-factors</td>\n",
       "      <td>TPOT</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>StandardScaler</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  dataset Framework sample_percentage feature_percentage  \\\n",
       "2                   adult      EDCA              0.63                1.0   \n",
       "2                   adult     FLAML              0.75                1.0   \n",
       "1                   adult      TPOT               NaN                NaN   \n",
       "0  amazon_employee_access      EDCA              0.75               0.56   \n",
       "0  amazon_employee_access     FLAML              0.75                1.0   \n",
       "0  amazon_employee_access      TPOT               1.0                1.0   \n",
       "1              australian      EDCA              0.33                1.0   \n",
       "1              australian     FLAML              0.75                1.0   \n",
       "2              australian      TPOT               1.0          0.5 (RFE)   \n",
       "3          bank-marketing      EDCA              0.64               0.69   \n",
       "3          bank-marketing     FLAML              0.75                1.0   \n",
       "3          bank-marketing      TPOT               NaN                NaN   \n",
       "4                  cnae-9      EDCA              0.75                1.0   \n",
       "4                  cnae-9     FLAML              0.75                1.0   \n",
       "4                  cnae-9      TPOT               1.0                1.0   \n",
       "5                credit-g      EDCA               0.5                1.0   \n",
       "5                credit-g     FLAML              0.75                1.0   \n",
       "5                credit-g      TPOT               NaN                NaN   \n",
       "6                kr-vs-kp      EDCA              0.75                1.0   \n",
       "6                kr-vs-kp     FLAML               NaN                NaN   \n",
       "6                kr-vs-kp      TPOT               NaN                NaN   \n",
       "7           mfeat-factors      EDCA              0.75               0.78   \n",
       "7           mfeat-factors     FLAML              0.75                1.0   \n",
       "7           mfeat-factors      TPOT               1.0                1.0   \n",
       "\n",
       "           scaler                                              model  \\\n",
       "2  StandardScaler                                      XGBClassifier   \n",
       "2             NaN                                     LGBMClassifier   \n",
       "1             NaN                                                NaN   \n",
       "0    MinMaxScaler                             RandomForestClassifier   \n",
       "0             NaN                                     LGBMClassifier   \n",
       "0             NaN  StackingEstimator (RandomForestClassifier, Ext...   \n",
       "1    MinMaxScaler                                      XGBClassifier   \n",
       "1             NaN                                      XGBClassifier   \n",
       "2             NaN                                     LGBMClassifier   \n",
       "3    MinMaxScaler                                      XGBClassifier   \n",
       "3             NaN                                     LGBMClassifier   \n",
       "3             NaN                                                NaN   \n",
       "4  StandardScaler                                 LogisticRegression   \n",
       "4             NaN                                      XGBClassifier   \n",
       "4             NaN  StackingEstimator (ExtraTreesClassifier, Stand...   \n",
       "5    RobustScaler                                 LogisticRegression   \n",
       "5             NaN                                     LGBMClassifier   \n",
       "5             NaN                                                NaN   \n",
       "6             NaN                             RandomForestClassifier   \n",
       "6             NaN                                                NaN   \n",
       "6             NaN                                                NaN   \n",
       "7  StandardScaler                                 LogisticRegression   \n",
       "7             NaN                                      XGBClassifier   \n",
       "7  StandardScaler                                 LogisticRegression   \n",
       "\n",
       "  categorical-imputer        encoder  \n",
       "2       SimpleImputer  OneHotEncoder  \n",
       "2                 NaN            NaN  \n",
       "1                 NaN            NaN  \n",
       "0                 NaN            NaN  \n",
       "0                 NaN            NaN  \n",
       "0                 NaN            NaN  \n",
       "1                 NaN            NaN  \n",
       "1                 NaN            NaN  \n",
       "2                 NaN            NaN  \n",
       "3                 NaN  OneHotEncoder  \n",
       "3                 NaN            NaN  \n",
       "3                 NaN            NaN  \n",
       "4                 NaN            NaN  \n",
       "4                 NaN            NaN  \n",
       "4                 NaN            NaN  \n",
       "5                 NaN  OneHotEncoder  \n",
       "5                 NaN            NaN  \n",
       "5                 NaN            NaN  \n",
       "6                 NaN  OneHotEncoder  \n",
       "6                 NaN            NaN  \n",
       "6                 NaN            NaN  \n",
       "7                 NaN            NaN  \n",
       "7                 NaN            NaN  \n",
       "7                 NaN            NaN  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.concat([edca_df, flaml_df, tpot_df])\n",
    "models.dataset = models.dataset.str.lower()\n",
    "models = models.sort_values(by=['dataset', 'Framework'])\n",
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in models.columns:\n",
    "    models.loc[models[col].isnull(), col] = '-'\n",
    "    models[col] = models[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_format = 'r|' * models.shape[1]\n",
    "column_format = column_format.removesuffix('|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "latex = models.to_latex(index=False,\n",
    "                  formatters={\"name\": str.upper},\n",
    "                  float_format=\"{:.2f}\".format,\n",
    "                  column_format=column_format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{r|r|r|r|r|r|r|r}\n",
      "\\toprule\n",
      "dataset & Framework & sample_percentage & feature_percentage & scaler & model & categorical-imputer & encoder \\\\\n",
      "\\midrule\n",
      "adult & EDCA & 0.63 & 1.0 & StandardScaler & XGBClassifier & SimpleImputer & OneHotEncoder \\\\\n",
      "adult & FLAML & 0.75 & 1.0 & - & LGBMClassifier & - & - \\\\\n",
      "adult & TPOT & - & - & - & - & - & - \\\\\n",
      "amazon_employee_access & EDCA & 0.75 & 0.56 & MinMaxScaler & RandomForestClassifier & - & - \\\\\n",
      "amazon_employee_access & FLAML & 0.75 & 1.0 & - & LGBMClassifier & - & - \\\\\n",
      "amazon_employee_access & TPOT & 1.0 & 1.0 & - & StackingEstimator (RandomForestClassifier, ExtraTreesClassifier) & - & - \\\\\n",
      "australian & EDCA & 0.33 & 1.0 & MinMaxScaler & XGBClassifier & - & - \\\\\n",
      "australian & FLAML & 0.75 & 1.0 & - & XGBClassifier & - & - \\\\\n",
      "australian & TPOT & 1.0 & 0.5 (RFE) & - & LGBMClassifier & - & - \\\\\n",
      "bank-marketing & EDCA & 0.64 & 0.69 & MinMaxScaler & XGBClassifier & - & OneHotEncoder \\\\\n",
      "bank-marketing & FLAML & 0.75 & 1.0 & - & LGBMClassifier & - & - \\\\\n",
      "bank-marketing & TPOT & - & - & - & - & - & - \\\\\n",
      "cnae-9 & EDCA & 0.75 & 1.0 & StandardScaler & LogisticRegression & - & - \\\\\n",
      "cnae-9 & FLAML & 0.75 & 1.0 & - & XGBClassifier & - & - \\\\\n",
      "cnae-9 & TPOT & 1.0 & 1.0 & - & StackingEstimator (ExtraTreesClassifier, StandardScaler, LogisticRegression) & - & - \\\\\n",
      "credit-g & EDCA & 0.5 & 1.0 & RobustScaler & LogisticRegression & - & OneHotEncoder \\\\\n",
      "credit-g & FLAML & 0.75 & 1.0 & - & LGBMClassifier & - & - \\\\\n",
      "credit-g & TPOT & - & - & - & - & - & - \\\\\n",
      "kr-vs-kp & EDCA & 0.75 & 1.0 & - & RandomForestClassifier & - & OneHotEncoder \\\\\n",
      "kr-vs-kp & FLAML & - & - & - & - & - & - \\\\\n",
      "kr-vs-kp & TPOT & - & - & - & - & - & - \\\\\n",
      "mfeat-factors & EDCA & 0.75 & 0.78 & StandardScaler & LogisticRegression & - & - \\\\\n",
      "mfeat-factors & FLAML & 0.75 & 1.0 & - & XGBClassifier & - & - \\\\\n",
      "mfeat-factors & TPOT & 1.0 & 1.0 & StandardScaler & LogisticRegression & - & - \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(latex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gputensorflow",
   "language": "python",
   "name": "gputensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
